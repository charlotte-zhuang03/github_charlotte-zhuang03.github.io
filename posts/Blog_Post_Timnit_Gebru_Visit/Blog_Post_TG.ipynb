{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f166bef-e972-4aa3-9c0f-7448c9b15335",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Blog Post: Learning from Timnit Gebru\"\n",
    "formet:\n",
    "  html:\n",
    "    code-fold: false\n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8dbad0-a18c-425b-8d4c-d42350b439eb",
   "metadata": {},
   "source": [
    "### About Dr. Timnit Gebru\n",
    "\n",
    "Dr. Timnit Gebru is a highly acclaimed computer scientist and an expert in algorithmic bias and data mining. She is renowned for her expertise in technology and artificial intelligence and is widely recognized for her research on bias and fairness in AI. \n",
    "\n",
    "Dr. Gebru co-founded Black in AI, an organization dedicated to increasing the representation of Black individuals in the field of artificial intelligence. She also founded the Distributed Artificial Intelligence Research Institute (DAIR). \n",
    "\n",
    "Dr. Gebru has authored several research papers on various AI-related topics, including Gender Shades, which examined gender bias in facial recognition software and found that Black women were 35% less likely to be recognized than White men, and On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?, which highlighted the risks associated with very large language models. \n",
    "\n",
    "She has been a vocal advocate for greater diversity in the field of AI and has called for greater consideration of the social and ethical implications of AI in the development and deployment of AI technologies. Dr. Gebru is also known for her departure from Google after being asked by high-level management to withdraw an unpublished paper or remove the names of all Google co-authors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf5be42-3cdb-4533-ab86-0b3167b2fdf7",
   "metadata": {},
   "source": [
    "### What is Happening at Middlebury\n",
    "\n",
    "Middlebury offers courses such as Artificial Intelligence and Machine Learning and regularly discusses topics related to ethics in AI. \n",
    "\n",
    "Like many other colleges, Middlebury is also facing the impact of ChatGPT. According to the Middlebury Campus Newspaper, the college has yet to establish a campus-wide policy regarding the use of ChatGPT or other AI tools, leaving the decision of whether to allow or prohibit such tools up to individual professors. However, there are ethical concerns associated with the use of ChatGPT and other AI tools. For instance, AI tools like ChatGPT and Grammarly have created a divide among students between those who can afford the premium version versus those who cannot, providing a significant advantage to students who can pay for premium features or information. Furthermore, large language models such as ChatGPT are trained on massive amounts of language data, which includes violent, racist, and sexist messages that people share online. Although developers try to mitigate such biased outputs before releasing ChatGPT, the chatbot still generates subtle and overt forms of bias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de64f63e-f9e7-45c6-88f7-8836f08e87dd",
   "metadata": {},
   "source": [
    "### Summary of Dr. Timnit Gebru's Talk\n",
    "\n",
    "In her talk, Dr. Timnit Gebru discussed the current applications of computer vision technology and expressed her concerns about their unreliability and bias. She highlighted examples such as Faception and Hirevue, which use facial images to judge people's personalities and emotions. Dr. Gebru emphasized that these measures cannot truly reflect a person's true pattern and, to a great extent, perpetuate structural racism. Faception, in particular, singles out individuals from marginalized groups as terrorists.\n",
    "\n",
    "Dr. Gebru also commented on the tendency of fields such as machine learning, computer vision, and data sciences to abstract things, which she believed was problematic since the application of AI is intended to deal with real people. She quoted Seeta Gangadharan's statement that \"papers tend to disappear people into mathematical equations,\" highlighting the importance of considering the human aspect when designing and implementing AI.\n",
    "\n",
    "The lack of diversity in datasets was another issue raised by Dr. Gebru. She cited her research on Gender Shades, which found that facial analysis datasets were predominantly composed of lighter-skinned individuals and males, leading to a high disparity in facial recognition results. Dr. Gebru also noted that while many people advocate for diversity in datasets, it is not enough to make things work equally well for everyone. Even if it does work for everyone, the situation can still be problematic. She discussed how some companies and institutions unethically gather \"diverse\" information by predatorily seeking more darker skin images and scraping images of transgender YouTubers without their consent.\n",
    "\n",
    "Moreover, Dr. Gebru stressed that technology is not always used in the way it is designed, and sometimes its use leads to more discrimination and problems than efficiency. People often rely too much on technology tools that ignore the real facts presented to them.\n",
    "\n",
    "Dr. Gebru suggested that we need to think beyond diversity in datasets and consider structural and real representation. She highlighted that panels mainly comprise individuals from dominant groups and those closest to money, which can marginalize vulnerable groups. She concluded that fairness is not only about datasets or math but also about society, and computer scientists should not shy away from this fact.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de85296a-d95f-4aac-a2d9-1c0cc5ac7d97",
   "metadata": {},
   "source": [
    "### Questions to Dr. Gebru\n",
    "\n",
    "- Considering the unreliable and biased nature of facial recognition tools, do you think it is necessary to prohibit or regulate the use of facial recognition on people, or to focus on improving the accuracy of the model and taking into account social factors? \n",
    "\n",
    "- How can computer vision technology assist marginalized communities, and what level of regulation do you believe is necessary?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml-0451] *",
   "language": "python",
   "name": "conda-env-ml-0451-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
